---
title: 'MATH 4025: Intro to Machine Learning'
---

```{python}
#| label: setup
#| include: false
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from ISLP import load_data
```

## Pre-Survey

Take 10 minute and fill our [this survey](https://forms.office.com/Pages/ResponsePage.aspx?id=221GfoWP4U6xMj_yZFxlSQJyt-ruO2lEkG4nYFtEh4RUNE80TE85UlZVQ0FGRjVZNVE1S1kwWVM4WiQlQCNjPTEu).

If you chose to opt-out please read as much of [this article](https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm) as you an in 8 minutes and then fill out [this survey](https://forms.office.com/r/E7nresw72K). 

## Data Generating Process

Suppose we have

-   Features: $\mathbf{X}$
-   Target: $Y$
-   Goal: Predict $Y$ using $\mathbf{X}$

. . .

-   **Data generating process**: underlying, unseen and unknowable
    process that generates $Y$ given $\mathbf{X}$

## Population

More mathematically, the "true"/population model can be represented by

$$Y=f(\mathbf{X}) + \epsilon$$

where $\epsilon$ is a **random** error term (includes measurement error,
other discrepancies) independent of $\mathbf{X}$ and has mean zero.

. . .

*GOAL*: Estimate $f$

## Why Estimate $f(\mathbf{X})$? {.smaller}

We wish to know about $f(\mathbf{X})$ for two reasons:

1.  Prediction: make an educated guess for what $y$ should be given a
    new $x_0$:
    $$\hat{y}_0=\hat{f}(x_0) \ 
    \text{or} \ 
    \hat{y}_0=\hat{C}(x_0)$$
2.  Inference: Understand the relationship between $\mathbf{X}$ and $Y$.

. . .

-   An ML algorithm that is developed mainly for predictive purposes is
    often termed as a **Black Box** algorithm.

## Prediction {.smaller}

There are two types of prediction problems:

-   **Regression** (response $Y$ is quantitative): Build a model
    $\\hat{Y} = \hat{f}(\\mathbf{X})$
-   **Classification** (response $Y$ is qualitative/categorical): Build
    a classifier $\\hat{Y}=\\hat{C}(\\mathbf{X})$

. . .

-   Note: a "hat", $\\hat{\\phantom{f}}$, over an object represents an
    estimate of that object
    -   E.g. $\\hat{Y}$ is an estimate of $Y$ and $\\hat{f}$ is an
        estimate of $f$

## Prediction and Inference

**Income dataset**

![Why ML? (from ISLR2)](images/02/2_2-1.png){.r-stretch}

## Prediction and Inference

**Income dataset**

::: {layout-ncol="2"}
![](images/02/2_3-1.png)

![](images/02/2_4-1.png)

Why ML? (from ISLR2)
:::

## [Question!!!]{style="color:blue"} {.smaller}

Based on the previous two slides, which of the following statements are
correct?

::: panel-tabset
## Questions

1.  As `Years of Education` increases, `Income` increases, keeping
    `Seniority` fixed.
2.  As `Years of Education` increases, `Income` decreases, keeping
    `Seniority` fixed.
3.  As `Years of Education` increases, `Income` increases.
4.  As `Seniority` increases, `Income` increases, keeping
    `Years of Education` fixed.
5.  As `Seniority` increases, `Income` decreases, keeping
    `Years of Education` fixed.
6.  As `Seniority` increases, `Income` increases.

## Answers

1.  As `Years of Education` increases, `Income` increases, keeping
    `Seniority` fixed. **TRUE**
2.  As `Years of Education` increases, `Income` decreases, keeping
    `Seniority` fixed. **FALSE**
3.  As `Years of Education` increases, `Income` increases. **TRUE**
4.  As `Seniority` increases, `Income` increases, keeping
    `Years of Education` fixed. **TRUE**
5.  As `Seniority` increases, `Income` decreases, keeping
    `Years of Education` fixed. **FALSE**
6.  As `Seniority` increases, `Income` increases. **TRUE**
:::

## Discussion

What's the difference between these two statements:

1.  As `Years of Education` increases, `Income` increases, keeping
    `Seniority` fixed.
2.  As `Years of Education` increases, `Income` increases.

<!-- ## [Question!!!]{style="color:blue"} {.smaller} -->

<!-- Which of the following statements are correct? -->

<!-- 1. The increase in `Income` resulting from increase in `Years of Education` keeping other variables fixed is **more** than the increase in `Income` resulting from increase in `Seniority` keeping other variables fixed. -->

<!-- 2. The increase in `Income` resulting from increase in `Years of Education` keeping other variables fixed is **less** than the increase in `Income` resulting from increase in `Seniority` keeping other variables fixed. -->

## How Do We Estimate $f(\mathbf{X})$?

Broadly speaking, we have two approaches.

1.  Parametric methods
2.  Non-parametric methods

## Parametric Methods

-   Assume a functional form for $f(\mathbf{X})$
    -   Linear Regression:
        $f(\mathbf{X})=\\beta_0 + \\beta_1 \\mathbf{x}_1 + \\beta_2 \\mathbf{x}_2 + \\ldots + \\beta_p \\mathbf{x}_p$
    -   Estimate the parameters $\\beta_0, \\beta_1, \\ldots, \\beta_p$
        using labeled data
-   Choosing $\\beta$'s that minimize some error metrics is called
    **fitting** the model
-   The data we use to fit the model is called our **training data**

## Parametric Methods {.smaller}

![Parametric model fit (from ISLR2)](images/02/2_2-1.png){.r-stretch}

::: incremental
-   What are some potential parametric models that could result in this
    picture?
-   Note: Right line is the true relationship
:::

## Parametric Methods {.smaller}

**Income dataset**

::: {layout-ncol="2"}
![True relationship](images/02/2_3-1.png){width="60%"}

![Parametric model](images/02/2_4-1.png){width="60%"}

From ISLR2
:::

::: incremental
-   What are some functions that could have resulted in the model on the
    right?
-   $\\text{Income} \\approx \\beta_0 + \\beta_1\\times\\text{Years of Education} + \\beta_2\\times\\text{Seniority}$
:::

## Non-parametric Methods {.smaller}

-   Non-parametric approach: no explicit assumptions about the
    functional form of $f(\mathbf{X})$
-   Much more observations (compared to a parametric approach) required
    to fit non-parametric model
    -   **Idea:** parametric model restricts space of possible answers

**Income dataset**

::: {layout-ncol="2"}
![True relationship](images/02/2_3-1.png){width="50%"}

![Non-parametric model fit](images/02/2_5-1.png){width="50%"}

From ISLR2
:::

## Supervised Learning: Flexibility of Models {.smaller}

-   Flexibility: smoothness of functions
-   More theoretically: how many parameters are there to estimate?

```{python}
#| echo: FALSE
#| label: fig-flexibility

np.random.seed(208)

# simulate data
x = np.random.uniform(low=20, high=40, size=100) # input/predictor
e = np.random.normal(loc=0, scale=1, size=100)   # error

a = 3
b = 0.87
c = 0.5

# true function
fx = a + (b * np.sqrt(x)) + (c * np.sin(x))

y = fx + e    # observed responses

toy_data = pd.DataFrame({'input': x, 'true_form': fx, 'response': y})

# Plotting
plt.figure(figsize=(10, 6))
sns.scatterplot(data=toy_data, x='input', y='response', color='black', alpha=0.5)

# True model
x_range = np.linspace(20, 40, 200)
true_y = a + (b * np.sqrt(x_range)) + (c * np.sin(x_range))
plt.plot(x_range, true_y, color='red', linewidth=2.5, label='true model')

# Linear model
sns.regplot(data=toy_data, x='input', y='response', scatter=False, color='blue', ci=None, label='linear model')

# Non-linear model (using polynomial or lowess for "flexibility" demonstration)
# Here reproducing the spirit of "more flexible" with a lowess smoother
from statsmodels.nonparametric.smoothers_lowess import lowess
# lowess returns (x_sorted, y_fitted)
z = lowess(y, x, frac=0.1) # frac=0.1 to make it wiggly/flexible
plt.plot(z[:, 0], z[:, 1], color='green', linewidth=2.5, label='non-linear model')

plt.title("Comparing two models", fontsize=20)
plt.ylabel("y")
plt.xlabel("x")
plt.legend()
plt.show()
```

[More flexible $\\implies$ More complex $\\implies$ Less Smooth $\\implies$
Less Restrictive $\\implies$ Less Interpretable

## Supervised Learning: Some Trade-offs {.smaller}

-   Prediction Accuracy versus Interpretability
-   Good Fit versus Over-fit or Under-fit

![Trade-off between flexibility and interpretability (from
ISLR2)](images/02/2_7-1-01.png)

## Supervised Learning: Selecting a Model {.smaller}

-   Why so many different ML techniques?
-   **There is no free lunch in statistics**: All methods have different
    pros and cons
    -   Must select correct model for each use-case
-   Relevant questions in model selection:
    -   How much observations $n$ and variables $p$? 
    -   What is the relative importance is prediction, interpretability, and inference? 
    -   Do we expect relationship to be non-linear?
    -   Regression or classification?

## Supervised Learning: Assessing Model Performance {.smaller}

-   When we estimate $f(\mathbf{X})$ using $\\hat{f}(\\mathbf{X})$, then,

$$\\underbrace{E\[Y-\\hat{Y}\]^2}_{Error}=E\[f(\mathbf{X})+\\epsilon - \\hat{f}(\\mathbf{X})\]^2=\\underbrace{E\[f(\mathbf{X})-\\hat{f}(\\mathbf{X})\]^2}_{Reducible} + \\underbrace{Var(\\epsilon)}_{Irreducible}$$

-   $E\[Y-\\hat{Y}\]^2$: Expected (average) squared difference
    between predicted and actual (observed) response, **Mean Squared Error (MSE)**
-   Goal: find an estimate of $f(\mathbf{X})$ to minimize the reducible
    error

## Supervised Learning: Assessing Model Performance {.smaller}

::: {style="font-size: 75%;"}
-   Labeled training data $(x_1,y_1), (x_2, y_2), \ldots, (x_n,y_n)$
    -   i.e. $n$ training observations
-   Fit/train a model from training data
    -   $\\hat{y}=\\hat{f}(x)$, regression
    -   $\\hat{y}=\\hat{C}(x)$, classification\
-   Obtain estimates $\\hat{f}(x_1), \\hat{f}(x_2), \ldots, \\hat{f}(x_n)$
    (or, $\\hat{C}(x_1), \\hat{C}(x_2), \ldots, \\hat{C}(x_n)$) of training
    data
-   Compute error:
    -   **Regression**
        $$\\text{Training MSE}=\\text{Average}_{Training} \\left(y-\\hat{f}(x)\right)^2 = \\frac{1}{n} \\displaystyle \\sum_{i=1}^{n} \\left(y_i-\\hat{f}(x_i)\right)^2$$ 
    -   **Classification** $$
        \\begin{aligned}
        \\text{Training Error Rate}
        & = \\text{Average}_{Training} \\ \\left[I \\left(y\ne\\hat{C}(x)\right) \\right]
        \\\\
        &= \\frac{1}{n} \\displaystyle \\sum_{i=1}^{n} \\ I\left(y_i \\ne \\hat{C}(x_i)\right)
        \\end{aligned}
        $$ 
:::

## Recap

-   Regression vs. Classification
-   Parametric vs. non-parametric models
-   Training v. test data
-   Assessing regression models: Mean-Squared Error
-   Trade-offs:
    +   Flexibility vs. interpretability
    +   Bias vs. variance
