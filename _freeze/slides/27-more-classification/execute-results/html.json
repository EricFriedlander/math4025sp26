{
  "hash": "ca122a78f0f3050aa5179ffc1d2bc260",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: 'MATH 427: More on Classification'\nauthor: Eric Friedlander\nfooter: \"[ðŸ”— MAT 427 - Spring 2025 -  Schedule](https://mat427sp25.netlify.app/schedule)\"\nlogo: \"../images/logo.png\"\nformat: \n  revealjs:\n    theme: slides.scss\n    multiplex: false\n    transition: fade\n    slide-number: false\n    incremental: false \n    chalkboard: true\nexecute:\n  freeze: auto\n  echo: true\n  cache: false\nknitr:\n  opts_chunk: \n    R.options:      \n    width: 200\n---\n\n\n\n\n## Computational Set-Up\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(rpart.plot)\nlibrary(knitr)\nlibrary(kableExtra)\n\ntidymodels_prefer()\n\nset.seed(427)\n```\n:::\n\n\n\n## Quick Review of Classification {.smaller}\n\n-   We've covered many different classification methods:\n    +   Logistic Regression (potentially with regularization)\n    +   KNN\n    +   Decision Tress\n    +   Random Forests\n    +   Gradient Boosted Trees\n-   For each of these methods, rank them as (high/medium/low) for each of the following criteria\n    +   Computational complexity to fit\n    +   Computational complexity to predict\n    +   Ability to handle non-linearity\n    +   Interpretability\n    +   Prediction accuracy\n    \n## Quick Review of Classification {.smaller}\n\n|         | Logistic Regression | KNN | Decision Trees | Random Forests | Gradient Boosted Trees |\n|----------|----------|----------|----------|----------|----------|\n| Comp. Fit    | Low     | Low     | Low     | Medium     | High     |\n| Comp. Pred.    | Low     | Depends     | Low     | Medium     | Medium     |\n| Non-linearity    | Low  | Medium     | Medium     | High     | High     |\n| Interp.    | High  | Low     | High     | Medium/Low     | Medium/Low     |\n| Acc.    | Low  | Depends     | Low     | Medium/High     | High     |\n\n\n## Data: Voter Frequency\n\n-   [Info about data](https://github.com/fivethirtyeight/data/tree/master/non-voters)\n-   Goal: Identify individuals who are unlikely to vote to help organization target \"get out the vote\" effort.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvoter_data <- read_csv('https://raw.githubusercontent.com/fivethirtyeight/data/master/non-voters/nonvoters_data.csv')\n\nvoter_clean <- voter_data |>\n  select(-RespId, -weight, -Q1) |>\n  mutate(\n    educ = factor(educ, levels = c(\"High school or less\", \"Some college\", \"College\")),\n    income_cat = factor(income_cat, levels = c(\"Less than $40k\", \"$40-75k \",\n                                               \"$75-125k\", \"$125k or more\")),\n    voter_category = factor(voter_category, levels = c(\"rarely/never\", \"sporadic\", \"always\"))\n  ) |>\n  filter(Q22 != 5 | is.na(Q22)) |>\n  mutate(Q22 = as_factor(Q22),\n         Q22 = if_else(is.na(Q22), \"Not Asked\", Q22),\n         across(Q28_1:Q28_8, ~if_else(.x == -1, 0, .x)),\n         across(Q28_1:Q28_8, ~ as_factor(.x)),\n         across(Q28_1:Q28_8, ~if_else(is.na(.x) , \"Not Asked\", .x)),\n         across(Q29_1:Q29_10, ~if_else(.x == -1, 0, .x)),\n         across(Q29_1:Q29_10, ~ as_factor(.x)),\n         across(Q29_1:Q29_8, ~if_else(is.na(.x) , \"Not Asked\", .x)),\n        Party_ID = as_factor(case_when(\n          Q31 == 1 ~ \"Strong Republican\",\n          Q31 == 2 ~ \"Republican\",\n          Q32 == 1  ~ \"Strong Democrat\",\n          Q32 == 2 ~ \"Democrat\",\n          Q33 == 1 ~ \"Lean Republican\",\n          Q33 == 2 ~ \"Lean Democrat\",\n          TRUE ~ \"Other\"\n        )),\n        Party_ID = factor(Party_ID, levels =c(\"Strong Republican\", \"Republican\", \"Lean Republican\",\n                                                \"Other\", \"Lean Democrat\", \"Democrat\", \"Strong Democrat\")),\n        across(!ppage, ~as_factor(if_else(.x == -1, NA, .x))))\n```\n:::\n\n\n\n## Split Data\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(427)\n\nvoter_splits <- initial_split(voter_clean, prop = 0.7, strata = voter_category)\nvoter_train <- training(voter_splits)\nvoter_test <- testing(voter_splits)\n```\n:::\n\n\n\n## Problem: More than two categories\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvoter_train |> \n  ggplot(aes(x = voter_category)) +\n  geom_bar()\n```\n\n::: {.cell-output-display}\n![](27-more-classification_files/figure-revealjs/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n\n## Define Model: Multinomial Regression\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmn_reg_model <- multinom_reg(mixture = 1, penalty = 0.005) |> # I chose this penalty arbitrarily\n  set_engine(\"glmnet\", family = \"multinomial\") |> \n  set_mode(\"classification\")\n```\n:::\n\n\n\n## Define Recipe\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmr_recipe <- recipe(voter_category ~ . , data = voter_train) |>\n  step_zv(all_predictors()) |>\n  step_integer(educ, income_cat, Party_ID, Q2_2:Q4_6, Q6, Q8_1:Q9_4, Q14:Q17_4,\n               Q25:Q26) |>\n  step_impute_median(all_numeric_predictors()) |>\n  step_impute_mode(all_nominal_predictors()) |>\n  step_dummy(all_nominal_predictors(), one_hot = FALSE) |> \n  step_normalize(all_numeric_predictors())\n```\n:::\n\n\n\n## Define Workflow and Fit\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmr_fit <- workflow() |>\n  add_model(mn_reg_model) |>\n  add_recipe(mr_recipe) |> \n  fit(voter_train)\n```\n:::\n\n\n\n## Look at Predictions\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmr_fit |> augment(new_data = voter_test) |> slice_sample(n=10) |> select(1:4) |> head() |>  kable()\n```\n\n::: {.cell-output-display}\n\n\n|.pred_class | .pred_rarely/never| .pred_sporadic| .pred_always|\n|:-----------|------------------:|--------------:|------------:|\n|sporadic    |          0.0317402|      0.5122327|    0.4560271|\n|always      |          0.0463060|      0.4464935|    0.5072005|\n|sporadic    |          0.0553279|      0.6529393|    0.2917328|\n|always      |          0.0388506|      0.4351109|    0.5260385|\n|always      |          0.0361359|      0.4164662|    0.5473979|\n|always      |          0.0991499|      0.4310622|    0.4697879|\n\n\n:::\n:::\n\n\n\n## Confusion Matrix\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmr_fit |> augment(new_data = voter_test) |> \n  conf_mat(truth = voter_category, estimate = .pred_class) |> autoplot(\"heatmap\")\n```\n\n::: {.cell-output-display}\n![](27-more-classification_files/figure-revealjs/unnamed-chunk-9-1.png){width=960}\n:::\n:::\n\n\n\n## Evaluating Multiclass Models {.smaller}\n\n-   No \"Positive\" and \"Negative\" anymore\n-   Accuracy: $$\\frac{\\text{Correct classifications}}{\\text{total observations}} = \\frac{285+559+221}{1746} \\approx 0.61$$\n-   Most of our metrics were based on having \"Positive\" vs. \"Negative\"\n    +   Precision/PPV\n    +   Recall/Sensitivity\n    +   Specificity\n    +   NPV\n    +   ROC/AUC\n    \n## Evaluating Multiclass Models\n\n-   Solution 1: Apply binary metrics to each class in turn\n    +   E.g. report three different Recall values\n        +   Rarely: $\\frac{285}{285+110+35} = \\approx 0.66$\n        +   Sporadic: $\\frac{559}{47+559+173} = \\approx 0.72$\n        +   Always: $\\frac{221}{21+301+221} = \\approx 0.41$\n-   Compute the Precision for each class:\n    +   Reminder: Precision = TP/(TP+FP)\n    \n## Solution 1 in R\n\n- No automatic implementation in yardstick (can hack together using `group_by` sometimes)\n\n:::: columns\n::: column\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmr_fit |> augment(new_data = voter_test) |> \n  group_by(voter_category) |> \n  recall(truth = voter_category, estimate = .pred_class) |> \n  kable()\n```\n\n::: {.cell-output-display}\n\n\n|voter_category |.metric |.estimator | .estimate|\n|:--------------|:-------|:----------|---------:|\n|rarely/never   |recall  |macro      | 0.6627907|\n|sporadic       |recall  |macro      | 0.7231565|\n|always         |recall  |macro      | 0.4069982|\n\n\n:::\n:::\n\n\n:::\n\n::: column\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmr_fit |> augment(new_data = voter_test) |> \n  group_by(voter_category) |> \n  recall(truth = voter_category, estimate = .pred_class) |> \n  kable()\n```\n\n::: {.cell-output-display}\n\n\n|voter_category |.metric |.estimator | .estimate|\n|:--------------|:-------|:----------|---------:|\n|rarely/never   |recall  |macro      | 0.6627907|\n|sporadic       |recall  |macro      | 0.7231565|\n|always         |recall  |macro      | 0.4069982|\n\n\n:::\n:::\n\n\n:::\n::::\n    \n## Evaluating Multiclass Models\n\n-   Solution 2: Average metrics across labels\n    +   *Macro-averaging* average one-versus-all metrics\n        +   Recall: $\\frac{0.66+0.72+0.41}{3} \\approx 0.60$\n    +   *Macro-weighted averaging* same but weight by class size\n        +   Recall: $\\frac{430\\times 0.66+773\\times 0.72+543\\times 0.41}{1746} \\approx 0.61$\n    +   *Micro-averaging* compute contribution for each class, aggregates them, then computes a single metric\n        +   Recall: $\\frac{285+559+221}{430+779+543} \\approx 0.61$\n        \n## Macro-Averaging in R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmr_fit |> augment(new_data = voter_test) |> \n  recall(truth = voter_category, estimate = .pred_class, estimator = \"macro\") |> \n  kable()\n```\n\n::: {.cell-output-display}\n\n\n|.metric |.estimator | .estimate|\n|:-------|:----------|---------:|\n|recall  |macro      | 0.5976485|\n\n\n:::\n:::\n\n\n        \n## Macro-Weighted Averaging in R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmr_fit |> augment(new_data = voter_test) |> \n  recall(truth = voter_category, estimate = .pred_class, estimator = \"macro_weighted\") |> \n  kable()\n```\n\n::: {.cell-output-display}\n\n\n|.metric |.estimator     | .estimate|\n|:-------|:--------------|---------:|\n|recall  |macro_weighted | 0.6099656|\n\n\n:::\n:::\n\n\n\n## Micro-Averaging in R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmr_fit |> augment(new_data = voter_test) |> \n  recall(truth = voter_category, estimate = .pred_class, estimator = \"micro\") |> \n  kable()\n```\n\n::: {.cell-output-display}\n\n\n|.metric |.estimator | .estimate|\n|:-------|:----------|---------:|\n|recall  |micro      | 0.6099656|\n\n\n:::\n:::\n\n\n\n## What if output is probability?\n\n-   For binary case we used ROC curve and AUC...\n-   Similar ideas apply here:\n    +   One vs. all\n    +   Macro Averaging\n    +   NO MICRO AVERAGING!\n    +   Hand and Till extension of AUC\n\n## Plotting one-vs.-all\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmr_fit |> augment(new_data = voter_test) |> \n  roc_curve(truth = voter_category, `.pred_rarely/never`, .pred_sporadic, .pred_always) |> \n  autoplot()\n```\n\n::: {.cell-output-display}\n![](27-more-classification_files/figure-revealjs/unnamed-chunk-15-1.png){width=960}\n:::\n:::\n\n\n\n## Macro Averaged AUC\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmr_fit |> augment(new_data = voter_test) |> \n  roc_auc(truth = voter_category, `.pred_rarely/never`, .pred_sporadic, .pred_always, \n          estimator = \"macro\") |> \n  kable()\n```\n\n::: {.cell-output-display}\n\n\n|.metric |.estimator | .estimate|\n|:-------|:----------|---------:|\n|roc_auc |macro      | 0.7802495|\n\n\n:::\n:::\n\n\n\n## Macro-Weighted Averaged AUC\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmr_fit |> augment(new_data = voter_test) |> \n  roc_auc(truth = voter_category, `.pred_rarely/never`, .pred_sporadic, .pred_always, \n          estimator = \"macro_weighted\") |> \n  kable()\n```\n\n::: {.cell-output-display}\n\n\n|.metric |.estimator     | .estimate|\n|:-------|:--------------|---------:|\n|roc_auc |macro_weighted | 0.7636223|\n\n\n:::\n:::\n\n\n\n## Hand and Till AUC\n\n-   [Paper](https://link.springer.com/article/10.1023/A:1010920819831)\n    +   Basic Idea: Do pairwise comparison of classes and average\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmr_fit |> augment(new_data = voter_test) |> \n  roc_auc(truth = voter_category, `.pred_rarely/never`, .pred_sporadic, .pred_always) |> \n  kable()\n```\n\n::: {.cell-output-display}\n\n\n|.metric |.estimator | .estimate|\n|:-------|:----------|---------:|\n|roc_auc |hand_till  | 0.7967478|\n\n\n:::\n:::\n\n\n\n## Discussion\n\nHow would heavily imbalanced classes impact each type of macro vs. micro averaging?\n\n# Dealing with Class-Imbalance\n\n##  Class-Imbalance\n\n-   Class-imbalance occurs where your the classes in your response greatly differ in terms of how common they are\n-   Occurs frequently:\n    +   Medicine: survival/death\n    +   Admission: enrollment/non-enrollment\n    +   Finance: repaid loan/defaulted\n    +   Tech: Clicked on ad/Didn't click\n    +   Tech: Churn rate\n    +   Finance: Fraud\n\n## Data: `haberman`\n\nStudy conducted between 1958 and 1970 at the University of Chicago's Billings Hospital on the survival of patients who had undergone surgery for breast cancer.\n\nGoal: predict whether a patient survived after undergoing surgery for breast cancer.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhaberman <- read_csv(\"../data/haberman.data\",\n                     col_names = c(\"Age\", \"OpYear\", \"AxNodes\", \"Survival\"))\nglimpse(haberman)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 306\nColumns: 4\n$ Age      <dbl> 30, 30, 30, 31, 31, 33, 33, 34, 34, 34, 34, 34, 34, 34, 35, 3â€¦\n$ OpYear   <dbl> 64, 62, 65, 59, 65, 58, 60, 59, 66, 58, 60, 61, 67, 60, 64, 6â€¦\n$ AxNodes  <dbl> 1, 3, 0, 2, 4, 10, 0, 0, 9, 30, 1, 10, 7, 0, 13, 0, 1, 0, 0, â€¦\n$ Survival <dbl> 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1â€¦\n```\n\n\n:::\n:::\n\n\n\n## Quick Clean\n\nStudy conducted between 1958 and 1970 at the University of Chicago's Billings Hospital on the survival of patients who had undergone surgery for breast cancer.\n\nGoal: predict whether a patient *died* after undergoing surgery for breast cancer.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhaberman <- haberman |> \n  mutate(Survival = factor(if_else(Survival == 1, \"Survived\", \"Died\"),\n                           levels = c(\"Died\", \"Survived\")))\nglimpse(haberman)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 306\nColumns: 4\n$ Age      <dbl> 30, 30, 30, 31, 31, 33, 33, 34, 34, 34, 34, 34, 34, 34, 35, 3â€¦\n$ OpYear   <dbl> 64, 62, 65, 59, 65, 58, 60, 59, 66, 58, 60, 61, 67, 60, 64, 6â€¦\n$ AxNodes  <dbl> 1, 3, 0, 2, 4, 10, 0, 0, 9, 30, 1, 10, 7, 0, 13, 0, 1, 0, 0, â€¦\n$ Survival <fct> Survived, Survived, Survived, Survived, Survived, Survived, Sâ€¦\n```\n\n\n:::\n:::\n\n\n\n## Split Data\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(427)\nhab_splits <- initial_split(haberman, prop = 0.75, strata = Survival)\nhab_train <- training(hab_splits)\nhab_test <- testing(hab_splits)\n```\n:::\n\n\n\n## Visualizing Response\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhab_train |> \n  ggplot(aes(y = Survival)) +\n  geom_bar()\n```\n\n::: {.cell-output-display}\n![](27-more-classification_files/figure-revealjs/unnamed-chunk-22-1.png){width=960}\n:::\n:::\n\n\n\n## Fitting Model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlr_fit <- logistic_reg() |> \n  set_engine(\"glm\") |> \n  fit(Survival ~ . , data = hab_train)\n```\n:::\n\n\n\n## Confusion Matrix\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlr_fit |> augment(new_data = hab_test) |> \n  conf_mat(truth = Survival, estimate = .pred_class) |> autoplot(\"heatmap\")\n```\n\n::: {.cell-output-display}\n![](27-more-classification_files/figure-revealjs/unnamed-chunk-24-1.png){width=960}\n:::\n:::\n\n\n\n## Performance Metrics\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhab_metrics <- metric_set(accuracy, precision, recall)\n\nlr_fit |> augment(new_data = hab_test) |> \n  roc_auc(truth = Survival, .pred_Died) |> kable()\n```\n\n::: {.cell-output-display}\n\n\n|.metric |.estimator | .estimate|\n|:-------|:----------|---------:|\n|roc_auc |binary     | 0.7284879|\n\n\n:::\n\n```{.r .cell-code}\nlr_fit |> augment(new_data = hab_test) |> \n  hab_metrics(truth = Survival, estimate = .pred_class) |> kable()\n```\n\n::: {.cell-output-display}\n\n\n|.metric   |.estimator | .estimate|\n|:---------|:----------|---------:|\n|accuracy  |binary     | 0.7692308|\n|precision |binary     | 0.8000000|\n|recall    |binary     | 0.1904762|\n\n\n:::\n:::\n\n\n\n## Recall is BAD!\n\n-   Since there are so few deaths, model always predicts a low probability of death\n-   Idea: just because you you have a HIGHER probability of death doesn't mean have a HIGH probability of death\n\n## What do we do?\n\n-   Depends on what your goal is...\n-   Ask yourself: What is most important to my problem?\n    +   Accurate probabilities?\n    +   Effective Separation?\n    +   Effective identification of positives?\n    +   Low false-positive rate?\n-   Discussion: Let's think of scenarios where each one of these is the most important.\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}