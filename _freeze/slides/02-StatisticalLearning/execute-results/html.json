{
  "hash": "47115470f6a82bd545dc5cd193cc4698",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Intro to Machine Learning\n---\n\n\n## Data Generating Process\n\nSuppose we have\n\n-   Features: $\\mathbf{X}$\n-   Target: $Y$\n-   Goal: Predict $Y$ using $\\mathbf{X}$\n\n. . .\n\n-   **Data generating process**: underlying, unseen and unknowable\n    process that generates $Y$ given $\\mathbf{X}$\n\n## Population\n\nMore mathematically, the \"true\"/population model can be represented by\n\n$$Y=f(\\mathbf{X}) + \\epsilon$$\n\nwhere $\\epsilon$ is a **random** error term (includes measurement error,\nother discrepancies) independent of $\\mathbf{X}$ and has mean zero.\n\n. . .\n\n*GOAL*: Estimate $f$\n\n## Why Estimate $f(\\mathbf{X})$? {.smaller}\n\nWe wish to know about $f(\\mathbf{X})$ for two reasons:\n\n1.  Prediction: make an educated guess for what $y$ should be given a\n    new $x_0$:\n    $$\\hat{y}_0=\\hat{f}(x_0) \\ \n    \\text{or} \\ \n    \\hat{y}_0=\\hat{C}(x_0)$$\n2.  Inference: Understand the relationship between $\\mathbf{X}$ and $Y$.\n\n. . .\n\n-   An ML algorithm that is developed mainly for predictive purposes is\n    often termed as a **Black Box** algorithm.\n\n## Prediction {.smaller}\n\nThere are two types of prediction problems:\n\n-   **Regression** (response $Y$ is quantitative): Build a model\n    $\\hat{Y} = \\hat{f}(\\mathbf{X})$\n-   **Classification** (response $Y$ is qualitative/categorical): Build\n    a classifier $\\hat{Y}=\\hat{C}(\\mathbf{X})$\n\n. . .\n\n-   Note: a \"hat\", $\\hat{\\phantom{f}}$, over an object represents an\n    estimate of that object\n    -   E.g. $\\hat{Y}$ is an estimate of $Y$ and $\\hat{f}$ is an\n        estimate of $f$\n\n## Prediction and Inference\n\n**Income dataset**\n\n![Why ML? (from ISLR2)](images/02/2_2-1.png){.r-stretch}\n\n## Prediction and Inference\n\n**Income dataset**\n\n::: {layout-ncol=\"2\"}\n![](images/02/2_3-1.png)\n\n![](images/02/2_4-1.png)\n\nWhy ML? (from ISLR2)\n:::\n\n## [Question!!!]{style=\"color:blue\"} {.smaller}\n\nConsider the previous two slides:\n\n1. What happens to `Income` as `Years of Education` increases? What is the difference between the information that the three plots (combine the first two) give you in answering this questions?\n2. 1. What happens to `Income` as `Seniority` increases? What is the difference between the information that the three plots (combine the first two) give you in answering this questions?\n\n## Discussion\n\nWhat's the difference between these two statements:\n\n1.  As `Years of Education` increases, `Income` increases, keeping\n    `Seniority` fixed.\n2.  As `Years of Education` increases, `Income` increases, without accounting for `Seniority`.\n\n## How Do We Estimate $f(\\mathbf{X})$?\n\nBroadly speaking, we have two approaches.\n\n1.  Parametric methods\n2.  Non-parametric methods\n\n## Parametric Methods\n\n-   Assume a functional form for $f(\\mathbf{X})$\n    -   Linear Regression:\n        $f(\\mathbf{X})=\\beta_0 + \\beta_1 \\mathbf{x}_1 + \\beta_2 \\mathbf{x}_2 + \\ldots + \\beta_p \\mathbf{x}_p$\n    -   Estimate the parameters $\\beta_0, \\beta_1, \\ldots, \\beta_p$\n        using labeled data\n-   Choosing $\\beta$'s that minimize some error metrics is called\n    **fitting** the model\n-   The data we use to fit the model is called our **training data**\n\n## Parametric Methods {.smaller}\n\n![Parametric model fit (from ISLR2)](images/02/2_2-1.png){.r-stretch}\n\n::: incremental\n-   What are some potential parametric models that could result in this\n    picture?\n-   Note: Right line is the true relationship\n:::\n\n## Parametric Methods {.smaller}\n\n**Income dataset**\n\n::: {layout-ncol=\"2\"}\n![True relationship](images/02/2_3-1.png){width=\"60%\"}\n\n![Parametric model](images/02/2_4-1.png){width=\"60%\"}\n\nFrom ISLR2\n:::\n\n::: incremental\n-   What are some functions that could have resulted in the model on the\n    right?\n-   $\\text{Income} \\approx \\beta_0 + \\beta_1\\times\\text{Years of Education} + \\beta_2\\times\\text{Seniority}$\n:::\n\n## Non-parametric Methods {.smaller}\n\n-   Non-parametric approach: no explicit assumptions about the\n    functional form of $f(\\mathbf{X})$\n-   Much more observations (compared to a parametric approach) required\n    to fit non-parametric model\n    -   **Idea:** parametric model restricts space of possible answers\n\n**Income dataset**\n\n::: {layout-ncol=\"2\"}\n![True relationship](images/02/2_3-1.png){width=\"50%\"}\n\n![Non-parametric model fit](images/02/2_5-1.png){width=\"50%\"}\n\nFrom ISLR2\n:::\n\n## Supervised Learning: Flexibility of Models {.smaller}\n\n-   Flexibility: smoothness of functions\n-   More theoretically: how many parameters are there to estimate?\n\n::: {#cell-fig-flexibility .cell execution_count=2}\n\n::: {.cell-output .cell-output-display execution_count=2}\n![](02-StatisticalLearning_files/figure-revealjs/fig-flexibility-output-1.png){#fig-flexibility width=960 height=480}\n:::\n:::\n\n\nMore flexible $\\implies$ More complex $\\implies$ Less Smooth $\\implies$\nLess Restrictive $\\implies$ Less Interpretable\n\n## Supervised Learning: Some Trade-offs {.smaller}\n\n-   Prediction Accuracy versus Interpretability\n-   Good Fit versus Over-fit or Under-fit\n\n![Trade-off between flexibility and interpretability (from\nISLR2)](images/02/2_7-1-01.png)\n\n## Supervised Learning: Selecting a Model {.smaller}\n\n-   Why so many different ML techniques?\n-   **There is no free lunch in statistics**: All methods have different\n    pros and cons\n    -   Must select correct model for each use-case\n-   Relevant questions in model selection:\n    -   How much observations $n$ and variables $p$? \n    -   What is the relative importance is prediction, interpretability, and inference? \n    -   Do we expect relationship to be non-linear?\n    -   Regression or classification?\n\n## Supervised Learning: Assessing Model Performance {.smaller}\n\n-   When we estimate $f(\\mathbf{X})$ using $\\hat{f}(\\mathbf{X})$, then,\n\n$$\n\\underbrace{E\\left[Y-\\hat{Y}\\right]^2}_{Error}=E\\left[f(\\mathbf{X})+\\epsilon - \\hat{f}(\\mathbf{X})\\right]^2=\\underbrace{E\\left[f(\\mathbf{X})-\\hat{f}(\\mathbf{X})\\right]^2}_{Reducible} + \\underbrace{Var(\\epsilon)}_{Irreducible}\n$$\n\n-   $E[Y-\\hat{Y}]^2$: Expected (average) squared difference\n    between predicted and actual (observed) response, **Mean Squared Error (MSE)**\n-   Goal: find an estimate of $f(\\mathbf{X})$ to minimize the reducible\n    error\n\n## Supervised Learning: Assessing Model Performance {.smaller}\n\n::: {style=\"font-size: 75%;\"}\n-   Labeled training data $(x_1,y_1), (x_2, y_2), \\ldots, (x_n,y_n)$\n    -   i.e. $n$ training observations\n-   Fit/train a model from training data\n    -   $\\hat{y}=\\hat{f}(x)$, regression\n    -   $\\hat{y}=\\hat{C}(x)$, classification\\\n-   Obtain estimates $\\hat{f}(x_1), \\hat{f}(x_2), \\ldots, \\hat{f}(x_n)$\n    (or, $\\hat{C}(x_1), \\hat{C}(x_2), \\ldots, \\hat{C}(x_n)$) of training\n    data\n-   Compute error:\n    -   **Regression**\n        $$\\text{Training MSE}=\\text{Average}_{Training} \\left(y-\\hat{f}(x)\\right)^2 = \\frac{1}{n} \\displaystyle \\sum_{i=1}^{n} \\left(y_i-\\hat{f}(x_i)\\right)^2$$ \n    -   **Classification** $$\n        \\begin{aligned}\n        \\text{Training Error Rate}\n        & = \\text{Average}_{Training} \\ \\left[I \\left(y\\ne\\hat{C}(x)\\right) \\right]\n        \\\\\n        &= \\frac{1}{n} \\displaystyle \\sum_{i=1}^{n} \\ I\\left(y_i \\ne \\hat{C}(x_i)\\right)\n        \\end{aligned}\n        $$ \n:::\n\n## Recap\n\n-   Regression vs. Classification\n-   Parametric vs. non-parametric models\n-   Training v. test data\n-   Assessing regression models: Mean-Squared Error\n-   Trade-offs:\n    +   Flexibility vs. interpretability\n    +   Bias vs. variance\n\n",
    "supporting": [
      "02-StatisticalLearning_files/figure-revealjs"
    ],
    "filters": [],
    "includes": {}
  }
}