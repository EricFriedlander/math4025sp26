{
  "hash": "0a9c23e6961e26f7111214038f9ea94d",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Homework 1: Exploratory Data Analysis\"\n---\n\n\nAdapted from \"Start teaching with R,\" created by R Pruim, N J Horton, and D Kaplan, 2013, \"Interactive and Dynamic Graphics for Data Analysis,\" by Dianne Cook and Deborah F. Swayne, Colby Long's DATA 325 Course at Wooster College and Maria Tackett's STA-210 course at Duke University.\n\n## Introduction\n\nIn this homework we will familiarize ourselves with the tools that we'll use throughout the course and refresh ourselves on topic related to exploratory data analysis.\n\n## Course Toolkit\n\nThe primary tools we'll be using in this course are **Python**, **Positron**, **git**, and **GitHub**. We will be using them throughout the course both to learn the concepts discussed in the course and to analyze real data and come to informed conclusions.\n\n::: callout-note\n**Python** is the programming language. **Positron** is the Integrated Development Environment (IDE) where we write code. **Miniforge/Conda** manages our Python installations and packages.\n:::\n\n::: callout-note\n**Git** is a version control system (like \"Track Changes\" but for code) and **GitHub** is the cloud hosting service for your Git projects.\n:::\n\nTo make versioning simpler, this homework will be completed individually. In the future, you'll learn about collaborating on GitHub.\n\n## Exploratory Data Analysis\n\nOne of the most important components of data science is exploratory data analysis. I really like the following definition, which comes from [this article](https://towardsdatascience.com/exploratory-data-analysis-8fc1cb20fd15) (though it's probably not the original source).\n\n> Exploratory Data Analysis refers to the critical process of performing initial investigations on data so as to discover patterns, spot anomalies, to test hypotheses and to check assumptions with the help of summary statistics and graphical representations.\n\nBefore you begin your exploratory analysis, you may already have a particular question in mind. For example, you might work for an online retailer and want to develop a model to predict which purchased items will be returned. Or, you may not have a particular question in mind. Instead, you might just be asked to look at browsing data for several customers and figure out some way to increase purchases. In either case, before you construct a fancy model, you need to explore and understand your data. This is how you gain new insights and determine if an idea is worth pursuing.\n\n## Learning goals\n\nBy the end of the homework, you will...\n\n-   Be familiar with the workflow using Python and GitHub\n-   Gain practice writing a reproducible report using Jupyter notebooks\n-   Practice version control using GitHub\n-   Be able to create numerical and visual summaries of data\n-   Use those summaries\n\n# Getting Started\n\n## Setting Up Your Environment\n\nBefore we analyze data, we need to set up our computer. This process involves installing a package manager (Miniforge), creating a virtual environment, and installing the necessary libraries.\n\n### Install Miniforge\n\nWe will use **Miniforge** to manage our Python installation. It pre-configures `conda` (package manager) and `mamba` (a faster version of conda) with the `conda-forge` channel, which is the community standard.\n\n1.  Go to the [Miniforge GitHub page](https://github.com/conda-forge/miniforge).\n2.  Download the **Miniforge3** installer for your operating system (Windows, macOS, or Linux).\n3.  Run the installer and follow the prompts.\n    *   *Windows*: Open \"Miniforge Prompt\" after installation to verify.\n    *   *Mac/Linux*: Open your terminal.\n\n### Create a Conda Environment\nWe never want to install packages into our \"base\" environment. Instead, we create a specific environment for this course.\n\nOpen your terminal (or Miniforge Prompt) and run:\n\n```bash\nmamba create -n math4025 python=3.14\n```\n*   `mamba create`: Command to create an environment.\n*   `-n math4025`: Names the environment \"math4025\".\n*   `python=3.14`: Specifies the Python version.\n\n### Activate the Environment\nTo use the environment, you must activate it:\n\n```bash\nmamba activate math4025\n```\nYou should see `(math4025)` appear in your prompt.\n\n### Install Packages\nNow we install the tools we need for this assignment.\n\n```bash\nmamba install pandas seaborn matplotlib plotnine itables jupyter pyreadr\n```\n*   `pandas`: Data manipulation.\n*   `seaborn`, `matplotlib`, `plotnine`: Data visualization.\n*   `itables`: Interactive tables.\n*   `jupyter`: Required to run Notebooks.\n\n## Setting up Positron & Git\n\n### Install Positron\nWe will use **Positron**, a new data science IDE from Posit (makers of RStudio).\n\n1.  Download and install [Positron](https://positron.posit.co/install.html).\n2.  Open Positron.\n3.  Select your Python Interpreter:\n    *   Open the Command Palette (`Ctrl+Shift+P` or `Cmd+Shift+P`).\n    *   Type `Python: Select Interpreter`.\n    *   Choose the `math4025` environment you just created.\n\n### Configure Git & GitHub\n\nYou need a **Personal Access Token (PAT)** to allow Positron to talk to GitHub securely.\n\n1.  Log in to [GitHub](https://github.com/).\n2.  Go to **Settings** > **Developer settings** > **Personal access tokens** > **Tokens (classic)**.\n3.  **Generate new token (classic)**.\n4.  Name it \"Math4025\", select the **`repo`** scope, and generate.\n5.  **Copy the token immediately!**\n6.  Configure Git on your machine (run in terminal):\n```bash\ngit config --global user.name \"Your Github Username\"\ngit config --global user.email \"your.email@example.com\"\n```\n7.  When asked for a password during cloning/pushing, paste your **PAT**.\n\n## The Assignment\n\nNow you will create your own Jupyter Notebook to analyze tipping data.\n\n### Clone the Repository\n\n1.  Go to the course [GitHub assignment](https://classroom.github.com/a/lqxGMOZJ).\n2.  Copy the HTTPS URL.\n3.  In Positron: `Control Palette` > `Git: Clone` > Paste URL.\n\n### Create Your Notebook\n\n1.  In Positron, create a new file named `hw01-analysis.ipynb` inside your repository folder.\n2.  Add a Markdown cell at the top with a title \"Homework 1: Exploratory Data Analysis\" and your name.\n\n\n## Understand Your Data\n\nToday we will be working with the `TIPS` data set which is in the `regclass` R package. I've saved the data as a csv and included it in the repo for this assignment. The data in the `TIPS` dataset is information recorded by one waiter about each tip he received over a period of a few months working in a restaurant. We would like to use this data to address the question, *\"What factors affect tipping behavior?\"*\n\nIn python you can `import` packages in a few ways:\n\n- `import pandas` will import pandas. Every time you want to use pandas you'll have to prepend `pandas.` (e.g. `pandas.read_csv()`)\n- `import pandas as pd` will import pandas and allow you to use the shorthand `pd` (e.g. `pd.read_csv()`)\n- `from pandas import *` will import everything from pandas (e.g. `read_csv()`)\n- `from pandas import read_csv()` will import only `read_csv()` (e.g. `read_csv()` will work but no other `pandas` functions will work)\n\nCommon conventions in data science:\n\n::: {#ea568595 .cell execution_count=2}\n``` {.python .cell-code}\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n```\n:::\n\n\n### Exercise 1\n\nIn your Jupyter notebook, create a code cell at the top and load `pandas`, `seaborn`, and `matplotlib.pyplot`.\n\n### Committing changes\n\nNow, go to the Source Control extension in the left-hand panel.\n\nIf you have made changes to your files, you should see it listed here. Clicking on these files shows you the difference between the last committed state of the document and its current state including changes. You should see deletions in red and additions in green.\n\nIf you're happy with these changes, we'll prepare the changes to be pushed to your remote repository. First, stage your changes by clicking the `+` button next to the file you want to stage. Next, write a meaningful commit message (for instance, \"update author name\") in the Commit message box. Finally, click Commit. Note that every commit needs to have a commit message associated with it.\n\nYou don't have to commit after every change, as this would get quite tedious. You should commit states that are meaningful to you for inspection, comparison, or restoration.\n\nIn the first few assignments I will nudge you when to commit and in some cases, what commit message to use. As the semester progresses we will let you make these decisions.\n\nNow let's make sure all the changes went to GitHub. Go to your GitHub repo and refresh the page. You should see your commit message next to the updated files. If you see this, all your changes are on GitHub and you're good to go!\n\n### Push changes\n\nNow that you have made an update and committed this change, it's time to push these changes to your repo on GitHub. There are a few ways to do this, if you're new to Git raise your hand or ask someone near you.\n\nIn order to push your changes to GitHub, you must have staged your commit to be pushed. \n\n#### Using the Command Line\n\nEventually you'll be better off using git from the terminal or command line:\n\n- `git add files-you-want-to-stage` or `git add .` to stage all files that have changed\n- `git commit -m \"This is your commit message\"`\n- `git push` to push your changes\n- `git pull` to pull changes from your remote repo\n\n\n### Exercise 2\n\nWhen exploring a new data set, itâ€™s important to first understand the basics. What format is our data in? What types of information are included in the data set? How many observations are there?\n\nIn the Python ecosystem, data sets are usually stored in a 2-dimensional structure called a **DataFrame**. The `pandas` library has long been the industry standard for data manipulation. After importing these libraries, you can get an idea of the structure of a data set using `df.info()`, and you can peek at the first few rows with `df.head()`. If you're used to using R, one thing you'll notice that all of these data manipulations are *methods* rather than functions. Create a code chunk and use these functions (and others) to better understand the data. Use `tips.head()`, `tips.info()`, or `tips.describe()` to explore the dataset. How many tips are recorded in this data set?\n\n### Exercise 3\n\nOften, a data set will come with a *code book* which gives more complete information about the structure of the data, the meaning of variables, and how the data were collected. In this case, most of the column names are pretty self explanatory.\n\n| Variable        | Description                               |\n|-----------------|-------------------------------------------|\n| `TipPercentage` | the gratuity, as a percentage of the bill |\n| `Bill`          | the cost of the meal in US dollars        |\n| `Tip`           | the tip in US dollars                     |\n| `Gender`        | gender of the bill payer                  |\n| `Smoker`        | whether the party included smokers        |\n| `Weekday`       | day of the week                           |\n| `Time`          | time the bill was paid                    |\n| `PartySize`     | size of the party                         |\n\nEven though the column names are self-explanatory, we might have more questions about the data. For example, we might conjecture that people tip differently for breakfast and lunch, but our data only tells us if the bill was paid at \"Day\" or \"Night.\" State another reasonable conjecture about a factor that might affect tipping behavior. What additional information would be helpful to explore that conjecture?\n\n::: {.callout-warning title=\"Render-Commit-Push\"}\nThis is a good place to render, commit, and push changes to your GitHub repo. Write an informative commit message (e.g. \"Complete exercises 1 - 3\"), and push every file to GitHub.\n:::\n\n# Numerical Summaries\n\nNow we'd like to start looking closely at the data set to develop some ideas about what factors might affect tipping. In **pandas**, basic descriptive statistics have intuitive names like `mean()`, `median()`, `std()`, and `quantile()`. When exploring your data, you typically use these methods directly on a DataFrame or Series, often in conjunction with `agg()` (similar to `summarize` in the tidyverse) to compute multiple statistics at once. We can apply these functions to an entire DataFrame or isolate a specific column using bracket notation.\n\n\n### Exercise 4\n\nUse some of these summaries to answer the following. How many smokers are in the data set? How fancy do you think restaurant is? Is it possible to tell from this summary how many different shifts the waiter worked? Why or why not?\n\nBefore we try to write any code, **write down the operations you want to do to get the answers**. For example, *count the number of rows in which the `Smoker` column has `Yes`*. We'll then translate that into code.\n\n### Exercise 5\n\nAs we start to explore different questions, we might want to know things about interactions between variables. Like, are tips larger during the day or at night? Or does gender or smoking status matter for how much people spend and how much they tip? In **pandas**, you can calculate statistics within groups using the `groupby` method followed by an aggregation function.\n\nCalculate the variance of the tip percentage broken down by day of the week. Do you notice anything unusual? Explore the data and determine a possible cause for this.\n\n\n### Exercise 6\n\nCreate the following plots using the library of your choice (`seaborn` or `plotnine`).\n\n*   **Plot 1**: A bar chart of `sex`.\n*   **Plot 2**: A histogram of `total_bill`.\n*   **Plot 3**: A scatterplot of `total_bill` vs `tip`, colored by `smoker`.\n\n### Exercise 7\n\nWhich day of the week has the highest *percentage* of tables that are smokers? Hint: look at documentation and use Google to figure out how to create table proportions.\n\n::: {.callout-warning title=\"Render-Commit-Push\"}\nThis is a good place to render, commit, and push changes to your hw-eda repo on GitHub. Write an informative commit message (e.g. \"Completed exercises 4 - 6\"), and push every file to GitHub by clicking the checkbox next to each file in the Git pane. After you push the changes, the Git pane in RStudio should be empty.\n:::\n\n## Graphical Summaries\n\nGraphical summaries are a key tool in exploratory data analysis to to help you understand your data. They also help you communicate insights about your data to others. For example, we might want to display relationships about some of our categorical variables. So we could start by graphing different party sizes in our data set.\n\nThere are a few different packages for generating plots in Python:\n\n- `matplotlib`: The foundational \"grandfather\" of Python plotting, offering granular low-level control for creating static, publication-quality figures, though often requiring verbose code.\n- `seaborn`: A high-level wrapper built on `matplotlib` that simplifies statistical visualization (like heatmaps and regression plots) with beautiful default themes and fewer lines of code.\n- `plotnine`: A strict implementation of the \"Grammar of Graphics\" (mimicking R's `ggplot2`), designed for users who prefer building plots by logically layering data, aesthetics, and geometries.\n- `plotly`: The best choice for **interactive** and web-ready charts, allowing users to zoom, pan, and hover over data points, making it ideal for dashboards.\n\n\n## Exercise 8\n\nCreate the following charts using `matplotlib`, `seaborn`, and `plotnine`.\n\n- Bar chart of `PartySize`\n- A stacked bar chart of `Weekday` broken down by `Smoker`\n- A standardized bar chart of `Weekday` broken down by `Smoker`\n- A histogram of `Tip` using 100 bins\n\n### Exercise 9\n\nNotice that there are a few \"spikes\" in the histogram above. What do you think is causing this?\n\nWe can also summarize this numerical data broken down by one of the categorical variables using boxplots, violin plots, or sina plots. \n\n\n#### `matplotlib`\n\n`matplotlib` offloads a lot of the data prepartion to you so you'll usually have to do some processing using `pandas`.\n\n::: {#b5af0365 .cell execution_count=3}\n``` {.python .cell-code}\n# Prepare data: Create a list of 'Tip' arrays, one for each 'Weekday'\ndays = tips['Weekday'].unique()\ndata_by_day = [tips[tips['Weekday'] == d]['Tip'] for d in days]\n\n# --- Plot 1: Boxplot ---\nplt.figure()\nplt.boxplot(data_by_day, labels=days)\nplt.title(\"Tips by Day of the Week\")\nplt.xlabel(\"Day of the Week\")\nplt.ylabel(\"Tips\")\nplt.show()\n\n# --- Plot 2: Boxplot + Jitter ---\nplt.figure()\nplt.boxplot(data_by_day, labels=days, showfliers=False) # Hide outliers to avoid dupes\n# Add jitter manually\nfor i, d in enumerate(days):\n    y = tips[tips['Weekday'] == d]['Tip']\n    x = np.random.normal(i + 1, 0.04, size=len(y)) # i+1 because boxplot is 1-indexed\n    plt.scatter(x, y, alpha=0.5, s=10, color='grey')\nplt.title(\"Tips by Day of the Week\")\nplt.xlabel(\"Day of the Week\")\nplt.ylabel(\"Tips\")\nplt.show()\n\n# --- Plot 3: Violin ---\nplt.figure()\nplt.violinplot(data_by_day, showmeans=False, showmedians=True)\nplt.xticks(ticks=range(1, len(days) + 1), labels=days)\nplt.title(\"Tips by Day of the Week\")\nplt.xlabel(\"Day of the Week\")\nplt.ylabel(\"Tips\")\nplt.show()\n\n# --- Plot 4: Sina Plot Approximation ---\n# Matplotlib has no native Sina plot. \n# A common approximation is a Violin plot with inner points (or a swarm plot).\n# Here we just show the violin (density) with scatter overlay.\nplt.figure()\nparts = plt.violinplot(data_by_day, showextrema=False)\nfor pc in parts['bodies']:\n    pc.set_facecolor('#D43F3A')\n    pc.set_alpha(0.3)\nfor i, d in enumerate(days):\n    y = tips[tips['Weekday'] == d]['Tip']\n    x = np.random.normal(i + 1, 0.04, size=len(y))\n    plt.scatter(x, y, alpha=0.6, s=10)\nplt.xticks(ticks=range(1, len(days) + 1), labels=days)\nplt.title(\"Tips by Day of the Week\")\nplt.xlabel(\"Day of the Week\")\nplt.ylabel(\"Tips\")\nplt.show()\n```\n:::\n\n\n#### `seaborn`\n\n`seaborn` codee looks a lot like `matplotlib` but takes care of most of the processing for you. However, `seaborn` tends to be a really slow package.\n\n::: {#71a6e4a0 .cell execution_count=4}\n``` {.python .cell-code}\n# --- Plot 1: Boxplot ---\nplt.figure()\nsns.boxplot(data=tips, x='Weekday', y='Tip')\nplt.title(\"Tips by Day of the Week\")\nplt.show()\n\n# --- Plot 2: Boxplot + Jitter ---\nplt.figure()\nsns.boxplot(data=tips, x='Weekday', y='Tip', fliersize=0) # Hide outliers\nsns.stripplot(data=tips, x='Weekday', y='Tip', jitter=True, color='black', alpha=0.5)\nplt.title(\"Tips by Day of the Week\")\nplt.show()\n\n# --- Plot 3: Violin ---\nplt.figure()\nsns.violinplot(data=tips, x='Weekday', y='Tip')\nplt.title(\"Tips by Day of the Week\")\nplt.show()\n\n# --- Plot 4: Sina Equivalent (Swarmplot or Violin+Strip) ---\n# Seaborn uses 'swarmplot' for non-overlapping points (beeswarm style)\nplt.figure()\nsns.violinplot(data=tips, x='Weekday', y='Tip', inner=None, color=\".8\")\nsns.stripplot(data=tips, x='Weekday', y='Tip', jitter=True)\nplt.title(\"Tips by Day of the Week\")\nplt.show()\n```\n:::\n\n\n#### `plotnine`\n\n`plotnine` mimicks `ggplot2` syntax (mostly). Note that you'll have to wrap your plots in parenthesis because Python can't follow the line breaks in the same way as R. In addition, if you want to create multiple plots in the same cell, you have two options. One option is to convert your `plotnine` plots into `matplotlib` objects using the `.draw()` method to convert a `plotnine` object into a `matplotlib` figure or `._draw_using_figure(fig, [ax])` to assign the `plotnine` object to an existing axis within a `matplotlib` figure. The second is to use `brick` from the package [`patchworklib`](https://github.com/ponnhide/patchworklib) which allows you to arrange figures.\n\n::: {#06ec8029 .cell execution_count=5}\n``` {.python .cell-code}\n# --- Plot 1: Boxplot ---\n(\n    ggplot(tips, aes(x='Weekday', y='Tip'))\n    + geom_boxplot()\n    + labs(title=\"Tips by Day of the Week\", x=\"Day of the Week\", y=\"Tips\")\n)\n\n# --- Plot 2: Boxplot + Jitter ---\n(\n    ggplot(tips, aes(x='Weekday', y='Tip'))\n    + geom_boxplot(outlier_shape=None) # Hide outliers so they aren't plotted twice\n    + geom_jitter(width=0.2)\n    + labs(title=\"Tips by Day of the Week\", x=\"Day of the Week\", y=\"Tips\")\n)\n\n# --- Plot 3: Violin ---\n(\n    ggplot(tips, aes(x='Weekday', y='Tip'))\n    + geom_violin()\n    + labs(title=\"Tips by Day of the Week\", x=\"Day of the Week\", y=\"Tips\")\n)\n\n# --- Plot 4: Sina ---\n(\n    ggplot(tips, aes(x='Weekday', y='Tip'))\n    + geom_sina()\n    + labs(title=\"Tips by Day of the Week\", x=\"Day of the Week\", y=\"Tips\")\n)\n```\n:::\n\n\n**final Task**: State a conjecture about tipping behavior (e.g., \"People tip more on weekends\"). Create **one plot** and **one summary table** to investigate your claim. Write a short sentence interpreting your findings.\n\n## Submission\n1.  Save your notebook.\n2.  In the Source Control tab (Git icon), **Stage** your changes.\n3.  **Commit** with a message like \"Finished HW01\".\n4.  **Push** to GitHub.\n\n",
    "supporting": [
      "01-hw-eda_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}