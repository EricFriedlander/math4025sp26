{
  "hash": "229a31c0a11ab859cbd3b7053bfbe0f6",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: 'MATH 427: Bagging and Boosting'\nauthor: Eric Friedlander\nfooter: \"[ðŸ”— MAT 427 - Spring 2025 -  Schedule](https://mat427sp25.netlify.app/schedule)\"\nlogo: \"../images/logo.png\"\nformat: \n  revealjs:\n    theme: slides.scss\n    multiplex: false\n    transition: fade\n    slide-number: false\n    incremental: false \n    chalkboard: true\nexecute:\n  freeze: auto\n  echo: true\n  cache: true\nknitr:\n  opts_chunk: \n    R.options:      \n    width: 200\n---\n\n\n\n\n## Computational Set-Up\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(rpart.plot)\nlibrary(knitr)\nlibrary(kableExtra)\n\ntidymodels_prefer()\n\nset.seed(427)\n```\n:::\n\n\n\n\n## Ensemble Methods\n\n-   Single regression or classification trees usually have poor predictive performance.\n-   **Ensemble Methods**: use a collection of models (in this case, decision trees) to improve the predictive performance\n    -   Downside: Interpretability\n-   Today:\n    -   Bagging\n    -   Random Forests\n    -   Boosting\n    \n## Flexibility vs. Interpretability\n\n![Adapted from ISLR, James et al.](images/25/2_7-1.png)\n\n## Bagging {.smaller}\n\n-   **Bootstrap aggregation** or **bagging** is a general-purpose procedure for reducing the variance of a statistical learning method.\n-   **Idea**: Build multiple trees and average their results.\n-   **Result**: Given a set of $n$ independent observations (random variables) $Z_1, \\ldots, Z_n$, each with variance $\\sigma^2$, the variance of the mean/average $\\bar{Z} = \\displaystyle \\dfrac{Z_1 + Z_2 + \\cdots + Z_n}{n}$ of the observations is $\\sigma^2/n$.\n    +   In other words, **averaging a set of observations reduces variance**.\n-   In reality, we do not have multiple training datasets.\n\n\n## Bootstrapping {.smaller}\n\n![Adapted from ISLR, James et al.](images/25/bootstrapping.png)\n\n## Bagging {.smaller}\n\n-   Take repeated bootstrap samples (say $B$) from the original dataset.\n-   Build tree on each bootstrap sample and obtain predictions $\\hat{f}^{*b}(x), \\ b=1, 2, \\ldots, B$.\n-   Average all the predictions: $$\\hat{f}_{\\text{bag}}(x) = \\frac{1}{B}\\sum_{i=1}^B\\hat{f}^{*b}(x)$$\n-   Trees not pruned: They have high variance, but low bias.\n-   Classification: **majority vote** the overall prediction is the most commonly occurring class among the $B$ predictions\n\n\n## Out-of-Bag Error Estimation {.smaller}\n\n-   Bagging $\\Rightarrow$ fitting lots of models $\\Rightarrow$ computationally taxing\n-   Bagging + Cross-validation $\\Rightarrow$ EXTREMELY COMPUTATIONALLY TAXING\n-   On average, each bagged tree (constructed on each bootstrap sample) makes use of around two-thirds of the observations.\n-   Remaining third observations referred to as **out-of-bag (OOB)** observations\n-   For $i^{th}$ observation, use the trees in which that observation was OOB. This will yield around $B/3$ predictions for the $i^{th}$ observation. Take their average to obtain a single prediction\n-   Equivalent to LOOCV if $B$ is large\n\n\n## Variable Importance Measures\n\n-   Bagging improves prediction accuracy at expense of interpretability\n-   Can still obtain overall summary of importance of each predictor\n    -   Reduction in the loss function (e.g., SSE) attributed to each variable at each split is tabulated\n    -   A single variable could be used multiple times in a tree\n    -   Total reduction in the loss function across all splits by a variable are summed up and used as the total feature importance\n    -   A large value indicates an important predictor.\n    \n# Bagging Implementation in R\n\n## Data: Voter Frequency\n\n-   [Info about data](https://github.com/fivethirtyeight/data/tree/master/non-voters)\n-   Goal: Identify individuals who are unlikely to vote to help organization target \"get out the vote\" effort.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvoter_data <- read_csv('https://raw.githubusercontent.com/fivethirtyeight/data/master/non-voters/nonvoters_data.csv')\n\nvoter_clean <- voter_data |> \n  select(-RespId, -weight, -Q1) |>\n  mutate(\n    educ = factor(educ, levels = c(\"High school or less\", \"Some college\", \"College\")),\n    income_cat = factor(income_cat, levels = c(\"Less than $40k\", \"$40-75k \",\n                                               \"$75-125k\", \"$125k or more\")),\n    voter_category = factor(voter_category, levels = c(\"rarely/never\", \"sporadic\", \"always\"))\n  ) |> \n  filter(Q22 != 5 | is.na(Q22)) |> \n  mutate(Q22 = as_factor(Q22),\n         Q22 = if_else(is.na(Q22), \"Not Asked\", Q22),\n         across(Q28_1:Q28_8, ~if_else(.x == -1, 0, .x)),\n         across(Q28_1:Q28_8, ~ as_factor(.x)),\n         across(Q28_1:Q28_8, ~if_else(is.na(.x) , \"Not Asked\", .x)),\n         across(Q29_1:Q29_10, ~if_else(.x == -1, 0, .x)),\n         across(Q29_1:Q29_10, ~ as_factor(.x)),\n         across(Q29_1:Q29_8, ~if_else(is.na(.x) , \"Not Asked\", .x)),\n        Party_ID = as_factor(case_when(\n          Q31 == 1 ~ \"Strong Republican\",\n          Q31 == 2 ~ \"Republican\",\n          Q32 == 1  ~ \"Strong Democrat\",\n          Q32 == 2 ~ \"Democrat\",\n          Q33 == 1 ~ \"Lean Republican\",\n          Q33 == 2 ~ \"Lean Democrat\",\n          TRUE ~ \"Other\"\n        )),\n        Party_ID = factor(Party_ID, levels =c(\"Strong Republican\", \"Republican\", \"Lean Republican\",\n                                                \"Other\", \"Lean Democrat\", \"Democrat\", \"Strong Democrat\")),\n        across(!ppage, ~as_factor(if_else(.x == -1, NA, .x))))\n```\n:::\n\n\n\n## Split Data\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(427)\n\nvoter_splits <- initial_split(voter_clean, prop = 0.7, strata = voter_category)\nvoter_train <- training(voter_splits)\nvoter_test <- testing(voter_splits)\n```\n:::\n\n\n\n## Define Model\n\n-   `trees`: kind of a tuning parameter... want to select value that is large enough but doesn't matter past that\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbagged_model <- rand_forest(trees = 500, mtry = .cols()) |> \n  set_engine(\"ranger\", importance = \"impurity\") |> \n  set_mode(\"classification\")\n```\n:::\n\n\n\n## Define Recipe\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbag_recipe <- recipe(voter_category ~ . , data = voter_train) |> \n  step_indicate_na(all_predictors()) |> \n  step_zv(all_predictors()) |> \n  step_integer(educ, income_cat, Party_ID, Q2_2:Q4_6, Q6, Q8_1:Q9_4, Q14:Q17_4,\n               Q25:Q26) |> \n  step_impute_median(all_numeric_predictors()) |> \n  step_impute_mode(all_nominal_predictors()) |> \n  step_dummy(all_nominal_predictors(), one_hot = TRUE)\n```\n:::\n\n\n\n## Define Workflow and Fit\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# need to install ranger\nbag_wf <- workflow() |> \n  add_model(bagged_model) |> \n  add_recipe(bag_recipe)\n\nbagged_fit <- bag_wf |> \n  fit(voter_train)\n```\n:::\n\n\n\n## Evaluate performance\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(bagged_fit, new_data = voter_test) |> \n  accuracy(truth = voter_category, estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 Ã— 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy multiclass     0.648\n```\n\n\n:::\n:::\n\n\n\n## Variable Importance\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(vip)\nvip(bagged_fit)\n```\n\n::: {.cell-output-display}\n![](25-bagging_files/figure-revealjs/unnamed-chunk-8-1.png){width=960}\n:::\n:::\n\n\n\n\n## Bagging: Disadvantages\n\n-   improves prediction performance but reduces interpretability\n-   trees in bagging not completely independent of each other since all the original features are considered at every split of every tree\n-   **tree correlation**: trees from different bootstrap samples typically have similar structure to each other (especially at the top of the tree)\n    -   prevents bagging from further reducing the variance of the individual models \n-   **Random forests** extend and improve upon bagged decision trees by reducing this correlation and thereby improving the accuracy of the overall ensemble.\n\n\n## Bagging: Disadvantages\n\n\n![Adapted from Hands-On Machine Learning, Boehmke & Greenwell](images/25/Boston-6-trees.png)\n\n# Random Forests\n\n## Random Forests {.smaller}\n\n-   **De-correlates** bagged trees $\\Rightarrow$ reducing variance\n-   As in bagging, we build a number of decision trees on bootstrapped training samples.\n-   Algorithm: do the following to build each tree\n    +   Generate bootstrapped sample of training data\n    +   Randomly select $m$ predictors\n    +   Pick best variable/split-oint from these $m$\n    +   Split node into two child nodes\n    +   Stop when typical stopped criteria is hit (not pruning)\n-   Note: A fresh sample of $m$ predictors is taken at each split\n-   Typically $m = p/3$ for regression and $m = \\sqrt{p}$ for classification but this should be considered a tuning parameter\n\n\n## Define Model\n\n-   `trees`: kind of a tuning parameter... want to select value that is large enough but doesn't matter past that\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_model <- rand_forest(trees = 100, mtry = tune()) |> \n  set_engine(\"ranger\", importance = \"impurity\") |> \n  set_mode(\"classification\")\n```\n:::\n\n\n\n## Define Recipe\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_recipe <- recipe(voter_category ~ . , data = voter_train) |> \n  step_indicate_na(all_predictors()) |> \n  step_zv(all_predictors()) |> \n  step_integer(educ, income_cat, Party_ID, Q2_2:Q4_6, Q6, Q8_1:Q9_4, Q14:Q17_4,\n               Q25:Q26) |> \n  step_impute_median(all_numeric_predictors()) |> \n  step_impute_mode(all_nominal_predictors()) |> \n  step_dummy(all_nominal_predictors(), one_hot = TRUE)\n```\n:::\n\n\n\n## Define Workflow and Fit\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# need to install ranger\nrf_wf <- workflow() |> \n  add_model(rf_model) |> \n  add_recipe(rf_recipe)\n```\n:::\n\n\n\n## Upper Limit for `mtry`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_model |> extract_parameter_set_dials()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCollection of 1 parameters for tuning\n\n identifier type    object\n       mtry mtry nparam[?]\n\nModel parameters needing finalization:\n   # Randomly Selected Predictors ('mtry')\n\nSee `?dials::finalize` or `?dials::update.parameters` for more information.\n```\n\n\n:::\n:::\n\n\n\n## Extract Number of Features\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_param <- rf_model |> extract_parameter_set_dials() |> finalize(voter_train)\nrf_param\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCollection of 1 parameters for tuning\n\n identifier type    object\n       mtry mtry nparam[+]\n```\n\n\n:::\n:::\n\n\n\n## Tune `mtry`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvoter_folds <- vfold_cv(voter_train, v = 5, repeats = 10, strata = voter_category)\n\nmtry_grid <- grid_regular(rf_param, levels = 10)\n\ntuning_results <- tune_grid(\n  rf_wf,\n  resamples= voter_folds,\n  grid = mtry_grid\n)\n```\n:::\n\n\n\n## Results\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(tuning_results)\n```\n\n::: {.cell-output-display}\n![](25-bagging_files/figure-revealjs/unnamed-chunk-15-1.png){width=960}\n:::\n:::\n\n\n\n## Evaluate performance\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_fit <-  rf_wf |> \n  finalize_workflow(select_best(tuning_results)) |> \n  fit(voter_train)\n\naugment(rf_fit, new_data = voter_test) |> \n  accuracy(truth = voter_category, estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 Ã— 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy multiclass     0.658\n```\n\n\n:::\n:::\n\n\n\n## Variable Importance\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(vip)\nvip(rf_fit)\n```\n\n::: {.cell-output-display}\n![](25-bagging_files/figure-revealjs/unnamed-chunk-17-1.png){width=960}\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}